"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4950],{54124:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/vision","metadata":{"permalink":"/TaskWeaver/blog/vision","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/vision.md","source":"@site/blog/vision.md","title":"Vision input for the Planner","description":"Introduction","date":"2025-03-13T00:00:00.000Z","tags":[],"readingTime":2.42,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null}],"frontMatter":{"title":"Vision input for the Planner","authors":"liqli","date":"2025-03-13T00:00:00.000Z"},"unlisted":false,"nextItem":{"title":"What makes a good agent reasoning framework?","permalink":"/TaskWeaver/blog/reasoning"}},"content":"## Introduction\\n\\nWe have supported vision input for the Planner role in TaskWeaver. \\nThe Planner role is responsible for generating the high-level plan for the task. \\nThe vision input is a new type of input that contains images. \\nThis feature is useful when the task requires visual understanding.\\n\x3c!-- truncate --\x3e\\n\\n## How vision input is supported in TaskWeaver\\n\\nIn TaskWeaver, we added a new role called `ImageReader` to read images and provide the image url (for remote images) or \\nthe image encoded in base64 (for local images) to the Planner role.\\nTo have this new role, you need to include it in the project configure file as follows:\\n\\n```json\\n{\\n    \\"session.roles\\": [\\n        \\"planner\\",\\n        \\"code_interpreter\\",\\n        \\"image_reader\\"\\n    ]\\n}\\n```\\n\\nThe ImageReader role takes the path or the url of the image as input and prepares a response Post for the Planner role. As described [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/gpt-with-vision?tabs=rest) for Azure OpenAI API, if the image is local, ImageReader need to encode the image in base64 and pass it to the API. If the image is remote, ImageReader need to provide the url of the image. \\nThe Planner role can then use the image information for various tasks.\\n\\n## An example\\n\\nLet\'s ask the agent to describe any uploaded image.\\n\\n\\n![image_reader](../static/img/image_reader.png)\\n\\nThe flow of the conversation is as follows:\\n```mermaid\\ngraph TD\\n    User --image path--\x3e Planner\\n    Planner --image path--\x3e ImageReader\\n    ImageReader --image encoded in Base64--\x3e Planner\\n    Planner --response--\x3e User\\n```\\n\\nIn the example above, the User talks to the agent in Web UI and uploads an image. \\nTaskWeaver also support providing the image path in console mode, either using the `/load` command or just include \\nthe image path in the input message.\\n\\n## Extension\\n\\nIf you look into the implementation of the ImageReader role, you will find that it is quite simple.\\nThe key logic is shown in the following code snippet:\\n\\n```python\\nif image_url.startswith(\\"http\\"):\\n    image_content = image_url\\n    attachment_message = f\\"Image from {image_url}.\\"\\nelse:\\n    if os.path.isabs(image_url):\\n        image_content = local_image_to_data_url(image_url)\\n    else:\\n        image_content = local_image_to_data_url(os.path.join(self.session_metadata.execution_cwd, image_url))\\n    attachment_message = f\\"Image from {image_url} encoded as a Base64 data URL.\\"\\n\\npost_proxy.update_attachment(\\n    message=attachment_message,\\n    type=AttachmentType.image_url,\\n    extra={\\"image_url\\": image_content},\\n    is_end=True,\\n)\\n```\\n\\nAfter the image url is obtained, the ImageReader role will encode the image in base64 if the image is local. \\nThen, it will create an attachment in the response Post and pass the image content to the Planner role.\\nTo achieve this, the attachment is created with the type `AttachmentType.image_url` and the image content is\\npassed as extra data with the key `image_url`.\\n\\nTherefore, if we want to support other scenarios with vision input, we can extend the ImageReader role by adding more logic \\nto handle different types of contents. One example is to support reading a document with text and images.\\nWe can add an attachment for each image in the document and pass the list of attachments to the Planner role."},{"id":"/reasoning","metadata":{"permalink":"/TaskWeaver/blog/reasoning","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/reasoning.md","source":"@site/blog/reasoning.md","title":"What makes a good agent reasoning framework?","description":"An agent can listen to the user\'s request, understand the context, make plans, take actions, observe the results, and respond to the user. Its behavior is driven by the reasoning process, which is the core of the agent\'s intelligence.","date":"2025-01-20T00:00:00.000Z","tags":[],"readingTime":18.26,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null}],"frontMatter":{"title":"What makes a good agent reasoning framework?","authors":"liqli","date":"2025-01-20T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Vision input for the Planner","permalink":"/TaskWeaver/blog/vision"},"nextItem":{"title":"Experience Selection in TaskWeaver","permalink":"/TaskWeaver/blog/experience"}},"content":"An agent can listen to the user\'s request, understand the context, make plans, take actions, observe the results, and respond to the user. Its behavior is driven by the reasoning process, which is the core of the agent\'s intelligence. \\n\\n\x3c!-- truncate --\x3e\\n\\nThere are many techniques developed to build an agent reasoning framework. For example, Chain-of-Thought (CoT) is one of the most popular reasoning approaches that uses a chain of thought to generate next-step actions. Another technique is ReAct, where the agent reflect on its action results to adjust its future actions. In TaskWeaver, one of the key reasoning technique is task decomposition and tracking, where the agent breaks down a task into subtasks and keeps track of the progress of each subtask. The following snippet shows an example of task decomposition and tracking in TaskWeaver:\\n\\n```commandline\\n\u251c\u2500\u25ba [init_plan]\\n\u2502   1. Request historical stock price data for MSFT from the user\\n\u2502   2. Request the forecasting model or method to be used for prediction <interactively depends on 1>\\n\u2502   3. Perform the prediction using the provided data and model <interactively depends on 2>\\n\u2502   4. Report the prediction results to the user <interactively depends on 3>\\n\u251c\u2500\u25ba [plan]\\n\u2502   1. Request historical stock price data for MSFT from the user\\n\u2502   2. Request the forecasting model or method to be used for prediction\\n\u2502   3. Perform the prediction using the provided data and model\\n\u2502   4. Report the prediction results to the user\\n\u251c\u2500\u25ba [current_plan_step] 1. Request historical stock price data for MSFT from the user\\n```\\n\\nThe agent lists the steps of the plan and the current step it is working on. While the agent is working on the task, it keeps track of the current step. This is useful especially when the task is complex and requires multiple steps to complete. The agent can refer to the current step to know what to do next. Without task decomposition and tracking, the agent may lose track of the task and fail to complete it. \\n\\nTaskWeaver also support ReAct-like reasoning. This is done by introducing multiple roles in the problem-solving process, especially the Planner and CodeInterpreter roles. The Planner role is responsible for planning the steps of the task, while the CodeInterpreter role is responsible for interpreting the code generated by the Planner. The Planner can reflect on the results of the CodeInterpreter and adjust the plan accordingly. In one round, the Planner and Code Interpreter can work together to complete a subtask with multiple interactions.\\n\\nHowever, there are still situations where the agent reasoning framework can be improved. If you have read the discussion above, you may have noticed that CoT is not implemented in TaskWeaver. \\n\\n**Why?**\\n\\nIn this article, we are focused on the reasoning in the Planner. In fact, the Code Interpreter has CoT implemented as shown in the following snippet:\\n\\n```commandline\\n\u251c\u2500\u25ba [thought] To fetch historical stock price data for MSFT using yfinance, I will first try to import yfinance and download the data. If yfinance is not installed, I will provide instructions to install it.\\n\u251c\u2500\u25ba [reply_type] python\\n\u251c\u2500\u25ba [reply_content]\\n\u2502   import yfinance as yf\\n\u2502\\n\u2502   # Fetch historical stock price data for MSFT\\n\u2502   ticker = \'MSFT\'\\n\u2502   msft_data = yf.download(ticker, start=\'2020-01-01\', end=\'2025-01-01\')\\n\u2502\\n\u2502   msft_data\\n```\\n\\nFor the Planner, there are actually two places in the response schema where CoT can be implemented: before generating the `init_plan` and after the `current_plan_step`, as shown in the previous snippet. The former is to generate the initial plan, while the latter is to use Planner\'s reasoning capabilities to solve the current subtask.\\n\\nThe former was not implemented in TaskWeaver for two reasons: (1) to simplify the schema and save the reasoning time/prompt size; (2) the existing `init_plan` and `plan` already represent a thought process, and adding CoT may not bring significant benefits. But as the LLM becomes faster and cheaper, it is possible to add CoT to the Planner to improve the planning quality.\\n\\nWith reasoning for planning, the output of the Planner looks like this:\\n\\n```commandline\\n Human   \u25b6  predict msft\'s stock price in the next 7 days\\n \u256d\u2500\u2500\u2500< Planner >\\n \u251c\u2500\u25ba [plan_reasoning] The user wants to predict Microsoft\'s stock price for the next 7 days. This task involves time series forecasting, which requires historical stock price data and a forecasting model. However, the user hasn\'t provided any data or specified a model to use. I need to ask the user for more information.\\n \u251c\u2500\u25ba [init_plan]\\n \u2502   1. Request historical stock price data from the user\\n \u2502   2. Ask the user to specify a forecasting model or confirm if a default model should be used\\n \u2502   3. Load the historical stock price data <interactively depends on 1>\\n \u2502   4. Train the forecasting model using the historical data <interactively depends on 2 and 3>\\n \u2502   5. Predict the stock price for the next 7 days <sequentially depends on 4>\\n \u2502   6. Report the prediction results to the user <interactively depends on 5>\\n```\\n\\nIt looks good, but it is not the most important part of this article. The latter is more interesting and also more challenging to implement than it looks.\\n\\nLet\'s use an example to motivate the necessity and explain the challenges. The task is described as follows and all the data in it are fake:\\n\\n```markdown\\n# Task Instructions  \\n## Step 1: Extract Employee Data  \\nExtract the following information from the employee summary:  \\n- `Employee ID`  \\n- `Department`  \\n- `Project Code`  \\n- `Role`  \\n- `Manager`  \\n- `Location`  \\n\\n### Employee Summary  \\nOn April 10, 2025, a review was conducted for an employee with ID `E12345`. \\nThe employee is part of the `Development` department and is currently assigned to project code `\\"X987\\"`. \\nThe role held is `\\"Software Engineer\\"` under the supervision of manager `\\"J. Doe.\\"` \\nThe primary work location is `\\"Remote.\\"`  \\n\\n## Step 2: Validate the Role  \\n- Confirm if the role is recognized among the following: Software Engineer, Data Analyst, Project Manager, DevOps Specialist, QA Tester.  \\n- Check if the role is one of the recognized roles.  \\n\\n## Step 3: Construct SQL Query  \\nPrepare and print the SQL query using the extracted details:  \\n===\\nSELECT EmployeeID, Department, ProjectCode, Role, Manager, Location  \\nFROM EmployeeRecords  \\nWHERE EmployeeID = \'{EmployeeID}\'  \\nAND Department = \'{Department}\'  \\nAND ProjectCode = \'{ProjectCode}\'  \\nAND Role = \'{Role}\'  \\nAND Manager = \'{Manager}\'  \\nAND Location = \'{Location}\'  \\nORDER BY EmployeeID;  \\n=== \\n```\\n\\nThe task has 3 steps: extract employee data, validate the role, and construct an SQL query. This would not be a hard problem for any ReAct based agents. Actually, for all the 3 steps, there is no need to call Code Interpreter. The Planner can reason through the task and generate the code directly. However, let\'s run it in TaskWeaver:\\n\\n```commandline\\n \u256d\u2500\u2500\u2500< Planner >\\n \u251c\u2500\u25ba [plan_reasoning] The user has provided a task with specific instructions to be followed step by step. The task involves extracting employee data, validating the role, and constructing an SQL query. Each step is dependent on\\n \u2502    the completion of the previous one, so they must be executed in sequence.\\n \u251c\u2500\u25ba [init_plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list <sequentially depends on 1>\\n \u2502   3. Construct the SQL query using the extracted details <sequentially depends on 2>\\n \u2502   4. Report the constructed SQL query to the user <interactively depends on 3>\\n \u251c\u2500\u25ba [plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list.\\n \u2502   3. Construct the SQL query using the extracted details.\\n \u2502   4. Report the constructed SQL query to the user.\\n \u251c\u2500\u25ba [current_plan_step] 1. Extract the specified employee data from the summary provided.\\n \u251c\u2500\u25ba [stop] InProcess\\n \u251c\u2500\u2500\u25cf Please extract the following information from the employee summary: Employee ID, Department, Project Code, Role, Manager, and Location. The summary is: On April 10, 2025, a review was conducted for an employee with ID     \\n \u2502   `E12345`. The employee is part of the `Development` department and is currently assigned to project code `\\"X987\\"`. The role held is `\\"Software Engineer\\"` under the supervision of manager `\\"J. Doe.\\"` The primary work        \\n \u2502   location is `\\"Remote.\\"`\\n \u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n \u2570\u2500\u2500\u25cf sending message to CodeInterpreter\\n \u256d\u2500\u2500\u2500< CodeInterpreter >\\n \u251c\u2500\u25ba [thought] I will extract the required information from the given employee summary using string manipulation techniques.\\n \u251c\u2500\u25ba [reply_type] python\\n \u251c\u2500\u25ba [reply_content]\\n \u2502   employee_summary = \\"On April 10, 2025, a review was conducted for an employee with ID `E12345`. The employee is part of the `Development` department and is currently assigned to project code \\\\\\"X987\\\\\\". The role held is      \\n \u2502   \\\\\\"Software Engineer\\\\\\" under the supervision of manager \\\\\\"J. Doe.\\\\\\" The primary work location is \\\\\\"Remote.\\\\\\"\\"\\n \u2502\\n \u2502   # Extracting information\\n \u2502   employee_id = employee_summary.split(\'ID `\')[1].split(\'`\')[0]\\n \u2502   department = employee_summary.split(\'`\')[3]\\n \u2502   project_code = employee_summary.split(\'project code \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   role = employee_summary.split(\'role held is \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   manager = employee_summary.split(\'manager \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   location = employee_summary.split(\'location is \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502\\n \u2502   employee_id, department, project_code, role, manager, location\\n \u251c\u2500\u25ba [verification] NONE\\n \u251c\u2500\u25ba [code_error] No code verification is performed.\\n \u251c\u2500\u25ba [execution_status] SUCCESS\\n \u251c\u2500\u25ba [execution_result]\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502\\n \u2502   The result of above Python code after execution is:\\n \u2502   (\'E12345\', \'Development\', \'X987\', \'Software Engineer\', \'J. Doe.\', \'Remote.\')\\n \u251c\u2500\u25ba [artifact_paths] []\\n \u251c\u2500\u2500\u25cf The following python code has been executed:\\n \u2502   ```python\\n \u2502   employee_summary = \\"On April 10, 2025, a review was conducted for an employee with ID `E12345`. The employee is part of the `Development` department and is currently assigned to project code \\\\\\"X987\\\\\\". The role held is      \\n \u2502   \\\\\\"Software Engineer\\\\\\" under the supervision of manager \\\\\\"J. Doe.\\\\\\" The primary work location is \\\\\\"Remote.\\\\\\"\\"\\n \u2502\\n \u2502   # Extracting information\\n \u2502   employee_id = employee_summary.split(\'ID `\')[1].split(\'`\')[0]\\n \u2502   department = employee_summary.split(\'`\')[3]\\n \u2502   project_code = employee_summary.split(\'project code \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   role = employee_summary.split(\'role held is \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   manager = employee_summary.split(\'manager \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502   location = employee_summary.split(\'location is \\\\\\"\')[1].split(\'\\\\\\"\')[0]\\n \u2502\\n \u2502   employee_id, department, project_code, role, manager, location\\n \u2502   ```\\n \u2502\\n \u2502\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502\\n \u2502   The result of above Python code after execution is:\\n \u2502   (\'E12345\', \'Development\', \'X987\', \'Software Engineer\', \'J. Doe.\', \'Remote.\')\\n \u2570\u2500\u2500\u25cf sending message to Planner\\n \u256d\u2500\u2500\u2500< Planner >\\n \u251c\u2500\u25ba [plan_reasoning] The employee data has been successfully extracted from the summary. The next step is to validate the role against the list of recognized roles.\\n \u251c\u2500\u25ba [init_plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list <sequentially depends on 1>\\n \u2502   3. Construct the SQL query using the extracted details <sequentially depends on 2>\\n \u2502   4. Report the constructed SQL query to the user <interactively depends on 3>\\n \u251c\u2500\u25ba [plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list.\\n \u2502   3. Construct the SQL query using the extracted details.\\n \u2502   4. Report the constructed SQL query to the user.\\n \u251c\u2500\u25ba [current_plan_step] 2. Validate the role against the recognized roles list.\\n \u251c\u2500\u25ba [stop] InProcess\\n \u251c\u2500\u2500\u25cf Please validate if the role \'Software Engineer\' is recognized among the following roles: Software Engineer, Data Analyst, Project Manager, DevOps Specialist, QA Tester.\\n \u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n \u2570\u2500\u2500\u25cf sending message to CodeInterpreter\\n \u256d\u2500\u2500\u2500< CodeInterpreter >\\n \u251c\u2500\u25ba [thought] I will validate if the role \'Software Engineer\' is recognized among the given list of roles.\\n \u251c\u2500\u25ba [reply_type] python\\n \u251c\u2500\u25ba [reply_content]\\n \u2502   # Step 2: Validate the Role\\n \u2502   recognized_roles = [\\"Software Engineer\\", \\"Data Analyst\\", \\"Project Manager\\", \\"DevOps Specialist\\", \\"QA Tester\\"]\\n \u2502   role = \\"Software Engineer\\"\\n \u2502\\n \u2502   is_role_recognized = role in recognized_roles\\n \u2502   is_role_recognized\\n \u251c\u2500\u25ba [verification] NONE\\n \u251c\u2500\u25ba [code_error] No code verification is performed.\\n \u251c\u2500\u25ba [execution_status] SUCCESS\\n \u251c\u2500\u25ba [execution_result]\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502\\n \u2502   The result of above Python code after execution is:\\n \u2502   True\\n \u251c\u2500\u25ba [artifact_paths] []\\n \u251c\u2500\u2500\u25cf The following python code has been executed:\\n \u2502   ```python\\n \u2502   # Step 2: Validate the Role\\n \u2502   recognized_roles = [\\"Software Engineer\\", \\"Data Analyst\\", \\"Project Manager\\", \\"DevOps Specialist\\", \\"QA Tester\\"]\\n \u2502   role = \\"Software Engineer\\"\\n \u2502\\n \u2502   is_role_recognized = role in recognized_roles\\n \u2502   is_role_recognized\\n \u2502   ```\\n \u2502\\n \u2502\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502   \\n \u2502   The result of above Python code after execution is:\\n \u2502   True\\n \u2570\u2500\u2500\u25cf sending message to Planner\\n \u256d\u2500\u2500\u2500< Planner >\\n \u251c\u2500\u25ba [plan_reasoning] The role \'Software Engineer\' is recognized among the list of roles. The next step is to construct the SQL query using the extracted details.\\n \u251c\u2500\u25ba [init_plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list <sequentially depends on 1>\\n \u2502   3. Construct the SQL query using the extracted details <sequentially depends on 2>\\n \u2502   4. Report the constructed SQL query to the user <interactively depends on 3>\\n \u251c\u2500\u25ba [plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list.\\n \u2502   3. Construct the SQL query using the extracted details.\\n \u2502   4. Report the constructed SQL query to the user.\\n \u251c\u2500\u25ba [current_plan_step] 3. Construct the SQL query using the extracted details.\\n \u251c\u2500\u25ba [stop] InProcess\\n \u251c\u2500\u2500\u25cf Please construct the SQL query using the extracted details: Employee ID \'E12345\', Department \'Development\', Project Code \'X987\', Role \'Software Engineer\', Manager \'J. Doe.\', and Location \'Remote\'. The SQL query should be  \\n \u2502   in the format provided in the task instructions.\\n \u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n \u2570\u2500\u2500\u25cf sending message to CodeInterpreter\\n \u256d\u2500\u2500\u2500< CodeInterpreter >\\n \u251c\u2500\u25ba [thought] I will construct the SQL query using the extracted details from the previous successful round.\\n \u251c\u2500\u25ba [reply_type] python\\n \u251c\u2500\u25ba [reply_content]\\n \u2502   # Step 3: Construct SQL Query\\n \u2502   employee_id = \'E12345\'\\n \u2502   department = \'Development\'\\n \u2502   project_code = \'X987\'\\n \u2502   role = \'Software Engineer\'\\n \u2502   manager = \'J. Doe.\'\\n \u2502   location = \'Remote.\'\\n \u2502\\n \u2502   sql_query = f\\"\\"\\"\\n \u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n \u2502   FROM EmployeeRecords\\n \u2502   WHERE EmployeeID = \'{employee_id}\'\\n \u2502   AND Department = \'{department}\'\\n \u2502   AND ProjectCode = \'{project_code}\'\\n \u2502   AND Role = \'{role}\'\\n \u2502   AND Manager = \'{manager}\'\\n \u2502   AND Location = \'{location}\'\\n \u2502   ORDER BY EmployeeID;\\n \u2502   \\"\\"\\"\\n \u2502\\n \u2502   sql_query\\n \u251c\u2500\u25ba [verification] NONE\\n \u251c\u2500\u25ba [code_error] No code verification is performed.\\n \u251c\u2500\u25ba [execution_status] SUCCESS\\n \u251c\u2500\u25ba [execution_result]\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502\\n \u2502   The result of above Python code after execution is:\\n \u2502\\n \u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n \u2502   FROM EmployeeRecords\\n \u2502   WHERE EmployeeID = \'E12345\'\\n \u2502   AND Department = \'Development\'\\n \u2502   AND ProjectCode = \'X987\'\\n \u2502   AND Role = \'Software Engineer\'\\n \u2502   AND Manager = \'J. Doe.\'\\n \u2502   AND Location = \'Remote.\'\\n \u2502   ORDER BY EmployeeID;\\n \u2502\\n \u251c\u2500\u25ba [artifact_paths] []\\n \u251c\u2500\u2500\u25cf The following python code has been executed:\\n \u2502   ```python\\n \u2502   # Step 3: Construct SQL Query\\n \u2502   employee_id = \'E12345\'\\n \u2502   department = \'Development\'\\n \u2502   project_code = \'X987\'\\n \u2502   role = \'Software Engineer\'\\n \u2502   manager = \'J. Doe.\'\\n \u2502   location = \'Remote.\'\\n \u2502\\n \u2502   sql_query = f\\"\\"\\"\\n \u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n \u2502   FROM EmployeeRecords\\n \u2502   WHERE EmployeeID = \'{employee_id}\'\\n \u2502   AND Department = \'{department}\'\\n \u2502   AND ProjectCode = \'{project_code}\'\\n \u2502   AND Role = \'{role}\'\\n \u2502   AND Manager = \'{manager}\'\\n \u2502   AND Location = \'{location}\'\\n \u2502   ORDER BY EmployeeID;\\n \u2502   \\"\\"\\"\\n \u2502\\n \u2502   sql_query\\n \u2502   ```\\n \u2502\\n \u2502\\n \u2502   The execution of the generated python code above has succeeded\\n \u2502\\n \u2502   The result of above Python code after execution is:\\n \u2502\\n \u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n \u2502   FROM EmployeeRecords\\n \u2502   WHERE EmployeeID = \'E12345\'\\n \u2502   AND Department = \'Development\'\\n \u2502   AND ProjectCode = \'X987\'\\n \u2502   AND Role = \'Software Engineer\'\\n \u2502   AND Manager = \'J. Doe.\'\\n \u2502   AND Location = \'Remote.\'\\n \u2502   ORDER BY EmployeeID;\\n \u2502\\n \u2570\u2500\u2500\u25cf sending message to Planner\\n \u256d\u2500\u2500\u2500< Planner >\\n \u251c\u2500\u25ba [plan_reasoning] The SQL query has been successfully constructed using the extracted employee details. The task is now complete, and the constructed SQL query can be reported to the user.\\n \u251c\u2500\u25ba [init_plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list <sequentially depends on 1>\\n \u2502   3. Construct the SQL query using the extracted details <sequentially depends on 2>\\n \u2502   4. Report the constructed SQL query to the user <interactively depends on 3>\\n \u251c\u2500\u25ba [plan]\\n \u2502   1. Extract the specified employee data from the summary provided.\\n \u2502   2. Validate the role against the recognized roles list.\\n \u2502   3. Construct the SQL query using the extracted details.\\n \u2502   4. Report the constructed SQL query to the user.\\n \u251c\u2500\u25ba [current_plan_step] 4. Report the constructed SQL query to the user.\\n \u251c\u2500\u25ba [stop] Completed\\n \u251c\u2500\u2500\u25cf The SQL query has been successfully constructed using the extracted details:\\n \u2502\\n \u2502   ```\\n \u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n \u2502   FROM EmployeeRecords\\n \u2502   WHERE EmployeeID = \'E12345\'\\n \u2502   AND Department = \'Development\'\\n \u2502   AND ProjectCode = \'X987\'\\n \u2502   AND Role = \'Software Engineer\'\\n \u2502   AND Manager = \'J. Doe.\'\\n \u2502   AND Location = \'Remote.\'\\n \u2502   ORDER BY EmployeeID;\\n \u2502   ```\\n \u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n \u2570\u2500\u2500\u25cf sending message to User\\n TaskWeaver \u25b6  The SQL query has been successfully constructed using the extracted details:\\n\\nSELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\nFROM EmployeeRecords\\nWHERE EmployeeID = \'E12345\'\\nAND Department = \'Development\'\\nAND ProjectCode = \'X987\'\\nAND Role = \'Software Engineer\'\\nAND Manager = \'J. Doe.\'\\nAND Location = \'Remote.\'\\nORDER BY EmployeeID;\\n```\\nThe log is quite lengthy, but it is quite clear and easy to understand. For each step, the Planner always asks the Code Interpreter to generate the code. Finally, the task is completed successfully. However, it is not the most efficient way to solve the task because the Planner can leverage its reasoning capabilities to extract information and construct the SQL query directly.\\n\\nWe have tried to add instructions in the Planner\'s prompt to emphasize the reasoning power, but the Planner still calls the Code Interpreter to generate the code. For a long time, we don\'t quite understand the reason behind this behavior. After many discussions and experiments, we finally realized that it is caused by the design of the Planner\'s response schema. The Planner needs to talk to another Role in the system each time. But if we want the Planner to use reasoning to solve the current subtask, who should the Planner talk to? Ideally, it should continue until the subtask that requires the Code Interpreter to generate the code. But how can we design the schema to support this? Because the Planner is explicitly tracking the progress, i.e., the `current_plan_step`, it is confusing to let the Planner continue the reasoning process through future steps. \\n\\nWe value the progress tracking more than the efficiency of the reasoning process, because this is critical for complex multi-step tasks. But we also want to improve the reasoning process to make the agent more intelligent. So, our choice is to add a special Role called `Recepta` to listen to the Planner\'s reasoning process when the Planner wants to use reasoning to solve the current subtask. The `Recepta` always answers \\"Got it. Please go ahead!\\" to the Planner. The Planner can then continue the reasoning process until the subtask that requires the Code Interpreter to generate the code. The `Recepta` is not a real Role in the system, but a design pattern to support the reasoning process in the Planner.\\n\\nNow, let\'s look at the output of TaskWeaver with `Recepta`:\\n\\n```commandline\\n\u256d\u2500\u2500\u2500< Planner >\\n\u251c\u2500\u25ba [plan_reasoning] The user has provided a set of instructions to follow step by step. The task involves extracting employee data from a summary, validating the role, and constructing an SQL query. I will follow these steps sequentially.\\n\u251c\u2500\u25ba [init_plan]\\n\u2502   1. Extract the following information from the employee summary: `Employee ID`, `Department`, `Project Code`, `Role`, `Manager`, `Location`\\n\u2502   2. Validate the role <interactively depends on 1>\\n\u2502   3. Construct and print the SQL query using the extracted details <interactively depends on 1>\\n\u2502   4. Check the execution result and report the result to the user <interactively depends on 1 and 3>\\n\u251c\u2500\u25ba [plan]\\n\u2502   1. Extract information from the employee summary\\n\u2502   2. Validate the role\\n\u2502   3. Construct SQL query using the extracted details\\n\u2502   4. Report the result to the user\\n\u251c\u2500\u25ba [current_plan_step] 1. Extract information from the employee summary\\n\u251c\u2500\u25ba [stop] InProcess\\n\u251c\u2500\u2500\u25cf Thought: I can read and comprehend the employee summary to extract the required information.\\n\u2502   Result: the `Employee ID` is `E12345`, the `Department` is `Development`, the `Project Code` is `X987`, the `Role` is `Software Engineer`, the `Manager` is `J. Doe`, and the `Location` is `Remote`.\\n\u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n\u2570\u2500\u2500\u25cf sending message to Recepta\\n\u256d\u2500\u2500\u2500< Recepta >\\n\u251c\u2500\u2500\u25cf Got it. Now, please go ahead!\\n\u2570\u2500\u2500\u25cf sending message to Planner\\n\u256d\u2500\u2500\u2500< Planner >\\n\u251c\u2500\u25ba [plan_reasoning] I have extracted the information from the employee summary. The next step is to verify if the role is one of the recognized roles.\\n\u251c\u2500\u25ba [init_plan]\\n\u2502   1. Extract the following information from the employee summary: `Employee ID`, `Department`, `Project Code`, `Role`, `Manager`, `Location`\\n\u2502   2. Validate the role <interactively depends on 1>\\n\u2502   3. Construct and print the SQL query using the extracted details <interactively depends on 1>\\n\u2502   4. Check the execution result and report the result to the user <interactively depends on 1 and 3>\\n\u251c\u2500\u25ba [plan]\\n\u2502   1. Extract information from the employee summary\\n\u2502   2. Validate the role\\n\u2502   3. Construct SQL query using the extracted details\\n\u2502   4. Report the result to the user\\n\u251c\u2500\u25ba [current_plan_step] 2. Validate the role\\n\u251c\u2500\u25ba [stop] InProcess\\n\u251c\u2500\u2500\u25cf Thought: I can verify if the role is one of the recognized roles with my pattern matching capability.\\n\u2502   Thought: The recognized roles are `Software Engineer, Data Analyst, Project Manager, DevOps Specialist, QA Tester`.\\n\u2502   Result: The role is `Software Engineer`, which is recognized.\\n\u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n\u2570\u2500\u2500\u25cf sending message to Recepta\\n\u256d\u2500\u2500\u2500< Recepta >\\n\u251c\u2500\u2500\u25cf Got it. Now, please go ahead!\\n\u2570\u2500\u2500\u25cf sending message to Planner\\n\u256d\u2500\u2500\u2500< Planner >\\n\u251c\u2500\u25ba [plan_reasoning] I can prepare and print the SQL query using the extracted details to the User.\\n\u251c\u2500\u25ba [init_plan]\\n\u2502   1. Extract the following information from the employee summary: `Employee ID`, `Department`, `Project Code`, `Role`, `Manager`, `Location`\\n\u2502   2. Validate the role <interactively depends on 1>\\n\u2502   3. Construct and print the SQL query using the extracted details <interactively depends on 1>\\n\u2502   4. Check the execution result and report the result to the user <interactively depends on 1 and 3>\\n\u251c\u2500\u25ba [plan]\\n\u2502   1. Extract information from the employee summary\\n\u2502   2. Validate the role\\n\u2502   3. Construct SQL query using the extracted details\\n\u2502   4. Report the result to the user\\n\u251c\u2500\u25ba [current_plan_step] 3. Construct and print the SQL query using the extracted details and report the result to the user\\n\u251c\u2500\u25ba [stop] Completed\\n\u251c\u2500\u2500\u25cf The role is `Software Engineer`, which is recognized.\\n\u2502\\n\u2502   Here is the SQL query using the extracted details:\\n\u2502   ```sql\\n\u2502   SELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\n\u2502   FROM EmployeeRecords\\n\u2502   WHERE EmployeeID = \'E12345\'\\n\u2502   AND Department = \'Development\'\\n\u2502   AND ProjectCode = \'X987\'\\n\u2502   AND Role = \'Software Engineer\'\\n\u2502   AND Manager = \'J. Doe\'\\n\u2502   AND Location = \'Remote\'\\n\u2502   ORDER BY EmployeeID;\\n\u2502   ```\\n\u251c\u2500\u25ba [shared_memory_entry] Add the plan to the shared memory\\n\u2570\u2500\u2500\u25cf sending message to User\\n TaskWeaver \u25b6  The role is `Software Engineer`, which is recognized.\\n\\nHere is the SQL query using the extracted details:\\n\\nSELECT EmployeeID, Department, ProjectCode, Role, Manager, Location\\nFROM EmployeeRecords\\nWHERE EmployeeID = \'E12345\'\\nAND Department = \'Development\'\\nAND ProjectCode = \'X987\'\\nAND Role = \'Software Engineer\'\\nAND Manager = \'J. Doe\'\\nAND Location = \'Remote\'\\nORDER BY EmployeeID;\\n```\\n\\nThe new log is not only shorter but also more efficient. It is also more reliable according to our observations. Writing code with regex to extract information from text is error-prone. \\n\\nIn summary, we have experimented the idea of adding a special Role called `Recepta` to support the reasoning process in the Planner. The `Recepta` is not a real Role in the system, but a design pattern to support the reasoning process in the Planner. This design pattern is simple and effective. It is also flexible and can be extended to support more complex reasoning processes in the Planner. We believe that this design pattern can be useful for building more intelligent agents in the future.\\n\\nTo enable it in TaskWeaver, the user needs to configure the roles in the configure file with the following content:\\n```json\\n\\"session.roles\\": [\\n    \\"planner\\",\\n    \\"code_interpreter\\",\\n    \\"recepta\\"\\n]\\n```\\nThe `recepta` role is added to the list of roles."},{"id":"/experience","metadata":{"permalink":"/TaskWeaver/blog/experience","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/experience.md","source":"@site/blog/experience.md","title":"Experience Selection in TaskWeaver","description":"We have introduced the motivation of the experience module in Experience","date":"2024-09-14T00:00:00.000Z","tags":[],"readingTime":3.82,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null}],"frontMatter":{"title":"Experience Selection in TaskWeaver","authors":"liqli","date":"2024-09-14T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"What makes a good agent reasoning framework?","permalink":"/TaskWeaver/blog/reasoning"},"nextItem":{"title":"Run TaskWeaver with Locally Deployed Not-that-Large Language Models","permalink":"/TaskWeaver/blog/local_llm"}},"content":"We have introduced the motivation of the `experience` module in [Experience](/docs/customization/experience) \\nand how to create a handcrafted experience in [Handcrafted Experience](/docs/customization/experience/handcrafted_experience).\\nIn this blog post, we discuss more advanced topics about the experience module on experience selection.\\n\\n## Static experience selection\\n\\nEvery role in TaskWeaver can configure its own experience directory, which can be configured \\nby setting the `role_name.experience_dir` field in the project configuration file.\\nFor the `Planner` and `CodeInterpreter` roles, you can configure the experience directory\\nby setting the `planner.experience_dir` and `code_generator.experience_dir` fields respectively.\\nThe default experience directory is `experience` in the project directory.\\n\\n\\n\\n:::info\\nThe role name is by default the name of the implementation file (without the extension) of the role unless\\nyou have specified the role name by calling `_set_name` in the implementation file.\\n:::\\n\\nBy configuring different experience directories for different roles, \\nyou can have different experiences for different roles in a static way.\\nUse the `Planner` role as an example, you can have the following project configuration file \\nto enable the experience selection for the `Planner` role.\\n\\n```json\\n{\\n  \\"planner.use_experience\\": true,\\n  \\"planner.experience_dir\\": \\"planner_exp_dir\\"\\n}\\n```\\n\\n\x3c!-- truncate --\x3e\\n\\n## Dynamic experience selection\\n\\nIn some cases, you may want to select the experience dynamically based on the input task.\\nIn TaskWeaver, although we retrieve the experience based on the query content,\\nit is sometimes difficult to obtain the right experience based solely on the similarity \\nbetween the query content and the experience content. \\n\\nOne real example we encountered is that we need to retrieve the experience based on the\\ntask type. We have many task types in the project, let\'s say `task_type_1`, `task_type_2`, and `task_type_3`.\\nEvery task type is about following a set of instructions to complete a task.\\nAlthough different task types have different instructions, the instructions are similar in structure.\\nFor example, they all have similar steps like `step_1`, `step_2`, and `step_3`, only \\nthe content of the steps is slightly different for different task types. \\nActually, even most of the step titles are the same for different task types.\\n\\nEach task type has its own experience, and we want to select the experience based on the task type.\\nEven though we can mix all the experiences into one experience directory, it is very hard \\nto differentiate the experiences based on the user input or the step content. \\nIn this project, the user input is simply a task ID, and we need to first figure out the task type based on the task ID,\\nand then select the experience based on the task type.\\n\\nTo achieve this, we add a layer in the experience selection process. Specifically, we allow\\nhaving subdirectories in the experience directory.\\nFor example, we can have the following experience directory structure:\\n\\n```\\nplanner_experience\\n\u251c\u2500\u2500 task_type_1\\n\u2502   \u251c\u2500\u2500 exp_1.yaml\\n\u2502   \u251c\u2500\u2500 exp_2.yaml\\n\u2502   \u2514\u2500\u2500 ...\\n```\\n\\nWhen we can identify the task type based on the task ID, we can set the experience subdirectory.\\nThis looks straightforward, but how can we set the experience subdirectory in TaskWeaver?\\nAs we need to do this in a dynamic way, the only way is to set the experience subdirectory in a [role](/docs/concepts/role).\\n\\nTaskWeaver recently introduced the concept of shared memory as discussed in [Shared Memory](/docs/memory).\\nShared memory allows a role to share information with other roles, and in this case, we can use shared memory to set the experience subdirectory.\\n\\nWe can add a new role called `TaskTypeIdentifier` to identify the task type based on the task ID.\\nThe key part of the `reply` function in `TaskTypeIdentifier` is shown below:\\n\\n```python\\ndef reply(self, memory: Memory, **kwargs: ...) -> Post:\\n    # ...\\n    # get the task type from the last post message\\n    task_type = get_task_type(last_post.message)\\n    # create an attachment \\n    post_proxy.update_attachment(\\n        type=AttachmentType.shared_memory_entry,\\n        message=\\"Add experience sub path\\",\\n        extra=SharedMemoryEntry.create(\\n            type=\\"experience_sub_path\\",\\n            scope=\\"conversation\\", # define the effective scope of the shared memory entry to be the whole conversation\\n            content=\\"task_type_1\\",\\n        ),\\n    )\\n\\n    return post_proxy.end()\\n```\\n\\nIn a role that needs to set the experience subdirectory, we can get the experience subdirectory from the shared memory.\\n\\n```python\\ndef reply(\\n        self,\\n        memory: Memory,\\n        post_proxy: Optional[PostEventProxy] = None,\\n        prompt_log_path: Optional[str] = None,\\n        **kwargs: ...,\\n    ) -> Post:\\n    ...\\n    rounds = memory.get_role_rounds(\\n        role=self.alias,\\n        include_failure_rounds=False,\\n    )\\n\\n    # obtain the query from the last round\\n    query = rounds[-1].post_list[-1].message\\n    \\n    # retrieve the experience based on the query\\n    self.role_load_experience(query=query, memory=memory)\\n    ...\\n```\\n\\n:::tip\\nThis is the current experimental feature in TaskWeaver which is subject to change.\\n:::\\n\\n## Conclusion\\n\\nIn this blog post, we have discussed how to select experiences in TaskWeaver.\\nWe have static experience selection by configuring the experience directory for each role.\\nTo enable dynamic experience selection, we have introduced the concept of shared memory to set the experience subdirectory."},{"id":"/local_llm","metadata":{"permalink":"/TaskWeaver/blog/local_llm","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/local_llm.md","source":"@site/blog/local_llm.md","title":"Run TaskWeaver with Locally Deployed Not-that-Large Language Models","description":"The feature introduced in this blog post can cause incompatibility issue with the previous version of TaskWeaver","date":"2024-07-08T00:00:00.000Z","tags":[],"readingTime":5.66,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null}],"frontMatter":{"title":"Run TaskWeaver with Locally Deployed Not-that-Large Language Models","authors":"liqli","date":"2024-07-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Experience Selection in TaskWeaver","permalink":"/TaskWeaver/blog/experience"},"nextItem":{"title":"Plugins In-Depth","permalink":"/TaskWeaver/blog/plugin"}},"content":":::info\\nThe feature introduced in this blog post can cause incompatibility issue with the previous version of TaskWeaver\\nif you have customized the examples for the planner and code interpreter. \\nThe issue is easy to fix by changing the examples to the new schema.\\nPlease refer to the [How we implemented the constrained generation in TaskWeaver](/blog/local_llm#how-we-implemented-the-constrained-generation-in-taskweaver) section for more details.\\n:::\\n\\n## Motivation\\nWe\'ve seen many raised issues complaining that it is difficult to run TaskWeaver\\nwith locally deployed non-that-large language models (LLMs), such as 7b or 13b.\\nWhen we examine the issues, we find that the main problem is that the models failed \\nto generate responses following our formatting instructions in the prompt. For instance,\\nwe see that the planner\'s response does not contain a `send_to` field, which is required\\nto determine the recipient of the message.\\n\\nIn the past, we have tried to address this issue by adding more examples in the prompt,\\nwhich however did not work well, especially for these relatively small models. Another idea\\nwas to ask the model to re-generate the response if it does not follow the format. \\nWe include the format error in the prompt to help the model understand the error and\\ncorrect it. However, this approach also did not work well. \\n\\n\x3c!-- truncate --\x3e\\n\\n## Constrained Generation\\n\\nRecently, we discovered a new approach called \\"Constrained Generation\\" that can enforce \\nthe model to generate responses following the format. Popular frameworks include [Outlines](https://github.com/outlines-dev/outlines),\\n[Guidance](https://github.com/guidance-ai/guidance), [lm-format-enforcer](https://github.com/noamgat/lm-format-enforcer/tree/main), etc.\\nAll these frameworks support generating responses following a specific format, e.g., a JSON schema.\\nThis makes it possible to control the output format by providing it a schema.\\n\\nIn TaskWeaver, a relatively easy way to integrate this feature is to use a local deployment that supports\\nboth constrained generation and OpenAI compatible API, for instance, the [vllm](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html).\\nThere are other frameworks that support constrained generation, such as llama.cpp. \\nBut currently, we found that this feature is still not mature enough, so we start with vllm for experimentation.\\n\\nTo run vllm, you can follow the instructions in the [vllm documentation](https://docs.vllm.ai/en/stable/serving/openai_compatible_server.html). \\nA simple example is shown below:\\n```shell\\npython -m vllm.entrypoints.openai.api_server --model meta-llama/Meta-Llama-3-8B-Instruct --guided-decoding-backend lm-format-enforcer\\n```\\nwhere `--guided-decoding-backend lm-format-enforcer` is used to enable the constrained generation feature and \\nspecify the backend. Currently, vllm only supports `lm-format-enforcer` and `outlines`.\\n\\nHere is a sample code to test the vllm server:\\n```python\\nfrom openai import OpenAI\\n\\njson_schema = {\\n    \\"type\\": \\"object\\",\\n    \\"properties\\": {\\n        \\"country_name\\": {\\n            \\"type\\": \\"string\\"\\n        }\\n    },\\n    \\"required\\": [\\"country_name\\"]\\n}\\n\\nopenai_api_key = \\"EMPTY\\"\\nopenai_api_base = \\"http://localhost:8000/v1\\"\\nclient = OpenAI(\\n    api_key=openai_api_key,\\n    base_url=openai_api_base,\\n)\\ncompletion = client.chat.completions.create(\\n    model=\\"meta-llama/Meta-Llama-3-8B-Instruct\\",\\n    messages = [\\n        {\\"role\\": \\"system\\", \\"content\\": \\"You are a helpful assistant.\\"},\\n        {\\"role\\": \\"user\\", \\"content\\": \\"Which country is San Francisco in?\\"}\\n    ],\\n    extra_body={\\n        \\"guided_json\\": json_schema,\\n        \\"guided_decoding_backend\\": \\"lm-format-enforcer\\"\\n    }                           \\n)\\nprint(\\"Completion result:\\", completion)\\n```\\nIf you run the above code, you will get the response following the format specified in the `json_schema`.\\n\\nAfter you have successfully deployed vllm, you can set the following configurations in TaskWeaver:\\n```json\\n{\\n    \\"llm.model\\": \\"meta-llama/Meta-Llama-3-8B-Instruct\\",\\n    \\"llm.api_base\\": \\"http://localhost:8000/v1\\",\\n    \\"llm.api_key\\": \\"null\\",\\n    \\"llm.api_type\\": \\"openai\\",\\n    \\"llm.openai.require_alternative_roles\\": false,\\n    \\"llm.openai.support_system_role\\": true\\n}\\n```\\nThe `llm.openai.require_alternative_roles` and `llm.openai.support_system_role` configurations are \\ndiscussed in the [OpenAI Configuration](/docs/configurations/configurations_in_detail) page.\\nWith these configurations, TaskWeaver will send the messages to the vllm server and get the responses.\\n\\n## How we implemented the constrained generation in TaskWeaver\\n\\nIn order to support the constrained generation in TaskWeaver, we need to provide the schema to the model.\\nTherefore, we made a few changes in the code to support this feature.\\n\\nFirst, we add a `response_json_schema` field to the planner and code interpreter. For planner, you can find\\nit in `taskweaver/planner/planner_prompt.py`. It looks like this:\\n```yaml\\nresponse_json_schema: |-\\n  {\\n    \\"type\\": \\"object\\",\\n    \\"properties\\": {\\n        \\"response\\": {\\n            \\"type\\": \\"object\\",\\n            \\"properties\\": {\\n                \\"init_plan\\": {\\n                    \\"type\\": \\"string\\"\\n                },\\n                \\"plan\\": {\\n                    \\"type\\": \\"string\\"\\n                },\\n                \\"current_plan_step\\": {\\n                    \\"type\\": \\"string\\"\\n                },\\n                \\"send_to\\": {\\n                    \\"type\\": \\"string\\"\\n                },\\n                \\"message\\": {\\n                    \\"type\\": \\"string\\"\\n                }\\n            },\\n            \\"required\\": [\\n                \\"init_plan\\",\\n                \\"plan\\",\\n                \\"current_plan_step\\",\\n                \\"send_to\\",\\n                \\"message\\"\\n            ]\\n        }\\n    },\\n    \\"required\\": [\\"response\\"]\\n  }\\n```\\nIf you are familiar with the previous output schema, you may notice that we have changed the `response` field to an object\\nfrom an array of elements. This is because that it is much easier to express the schema in JSON format if \\nthe properties are in an object, not elements in an array.\\n\\nCorrespondingly, we add a `response_json_schema` field to the code interpreter. You can find it in `taskweaver/code_interpreter/code_interpreter/code_generator_prompt.py`,\\nwhich looks like this:\\n```yaml\\nresponse_json_schema: |-\\n    {\\n        \\"type\\": \\"object\\",\\n        \\"properties\\": {\\n            \\"response\\": {\\n                \\"type\\": \\"object\\",\\n                \\"properties\\": {\\n                    \\"thought\\": {\\n                        \\"type\\": \\"string\\"\\n                    },\\n                    \\"reply_type\\": {\\n                        \\"type\\": \\"string\\",\\n                        \\"enum\\": [\\"python\\", \\"text\\"]\\n                    },\\n                    \\"reply_content\\": {\\n                        \\"type\\": \\"string\\"\\n                    }   \\n                },\\n                \\"required\\": [\\"thought\\", \\"reply_type\\", \\"reply_content\\"]\\n            }\\n        },\\n        \\"required\\": [\\"response\\"]\\n    } \\n```\\nWe also change the `response` field to an object from an array of elements in the code interpreter.\\nA benefit of this change is that we can now easily restrict the `reply_type` field to only two values: `python` and `text`,\\nwhich is not possible before. \\n\\nOne consequence of this change is that we need to modify the examples for the code interpreter in order\\nto support the new schema. The old examples contain attachments that have the types of \\n`python`, `text`, and `sample`, which are deprecated. We now need to change them to the new schema.\\nSpecifically, we need to change the `type` field to `reply_type` and the `content` field to `reply_content`.\\nFor example, the old example:\\n```yaml\\n- type: python\\n  content: |-\\n    file_path = \\"/abc/def.txt\\"  \\n\\n    with open(file_path, \\"r\\") as file:  \\n        file_contents = file.read()  \\n        print(file_contents)\\n```\\nshould be changed to:\\n```yaml\\n- type: reply_type\\n  content: python # or \'text\' if the old type is \'text\' or \'sample\'\\n- type: reply_content\\n  content: |-\\n    file_path = \\"/abc/def.txt\\"  \\n\\n    with open(file_path, \\"r\\") as file:  \\n        file_contents = file.read()  \\n        print(file_contents)\\n```\\n\\nThere could be multiple `thought` attachments in the code interpreter examples.\\nBut in the new schema, there is only one `thought` field. So we have added code to do the conversion and no \\nmanual work is needed to modify the examples.\\nIf you have examples, after these changes, we can now support the constrained generation in TaskWeaver.\\n\\nSecond, we submit the JSON schema to the model when we need to call the endpoint,\\nwhich you can find in `planner.py` and `code_generator.py`, respectively.\\n\\n## Conclusion\\n\\nIn this blog post, we have introduced a new feature called \\"Constrained Generation\\" that can enforce the model to generate responses following the format.\\nWe have also shown how to run TaskWeaver with locally deployed non-that-large language models (LLMs) that support constrained generation.\\nWe have also explained how we implemented the constrained generation in TaskWeaver. We hope this feature can help you run TaskWeaver with LLMs more easily.\\nIf you have any questions or suggestions, please feel free to contact us."},{"id":"/plugin","metadata":{"permalink":"/TaskWeaver/blog/plugin","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/plugin.md","source":"@site/blog/plugin.md","title":"Plugins In-Depth","description":"**Pre-requisites**: Please refer to the Introduction and the Plugin Development","date":"2024-05-23T00:00:00.000Z","tags":[],"readingTime":4.74,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null}],"frontMatter":{"title":"Plugins In-Depth","authors":"liqli","date":"2024-05-23T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Run TaskWeaver with Locally Deployed Not-that-Large Language Models","permalink":"/TaskWeaver/blog/local_llm"},"nextItem":{"title":"How to evaluate a LLM agent?","permalink":"/TaskWeaver/blog/evaluation"}},"content":"_**Pre-requisites**: Please refer to the [Introduction](/docs/plugin/plugin_intro) and the [Plugin Development](/docs/plugin/how_to_develop_a_new_plugin) \\npages for a better understanding of the plugin concept and its development process._\\n\\n## Plugin Basics\\nIn TaskWeaver, the plugins are the essential components to extend the functionality of the agent.\\nSpecifically, a plugin is a piece of code wrapped in a class that can be called as a function by the agent in the generated code snippets.\\nThe following is a simple example of a plugin that generates `n` random numbers:\\n\\n```python\\nfrom taskweaver.plugin import Plugin, register_plugin\\n\\n@register_plugin\\nclass RandomGenerator(Plugin):\\n    def __call__(self, n: int):\\n        import random\\n        return [random.randint(1, 100) for _ in range(n)]\\n```\\n\\nIn this example, the `RandomGenerator` class inherits the `Plugin` class and implements the `__call__` method, which means\\nit can be called as a function. What would be the function signature of the plugin? \\nIt is defined in the associated YAML file. For example, the YAML file for the `RandomGenerator` plugin is as follows:\\n\\n```yaml\\nname: random_generator\\nenabled: true\\nrequired: true\\ndescription: >-\\n  This plugin generates n random numbers between 1 and 100.\\nexamples: |-\\n  result = random_generator(n=5)\\nparameters:\\n  - name: n\\n    type: int\\n    required: true\\n    description: >-\\n      The number of random numbers to generate.\\n\\nreturns:\\n  - name: result\\n    type: list\\n    description: >-\\n      The list of random numbers.\\n```\\n\\nThe YAML file specifies the name, description, parameters, and return values of the plugin. \\nWhen the LLM generates the code snippets, it will use the information in the YAML file to generate the function signature.\\nWe did not check the discrepancy between the function signature in the Python implementation and the YAML file. \\nSo, it is important to keep them consistent.\\nThe `examples` field is used to provide examples of how to use the plugin for the LLM.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Configurations and States\\n\\nAlthough the plugin is used as a function in the code snippets, it is more than a normal Python function.\\nThe plugin can have its own configurations and states.\\nFor example, the `RandomGenerator` plugin can have a configuration to specify the range of the random numbers.\\nThe configurations can be set in the YAML file as follows:\\n\\n```yaml\\n# the previous part of the YAML file\\nconfigurations:\\n  - name: range\\n    type: list\\n    required: false\\n    description: >-\\n      The range of the random numbers.\\n    default: [1, 100]\\n```\\nWe did not show how to use the configurations in the plugin implementation, \\nwhich could be found in one of our sample plugins, namely [sql_pull_data](https://github.com/microsoft/TaskWeaver/blob/main/project/plugins/sql_pull_data.yaml).\\nSupporting configurations in the plugin is a powerful feature to make the plugin more flexible and reusable.\\nFor example, we can have multiple YAML files pointing to the same Python implementation but with different configurations.\\nRead this [page](/docs/plugin/multi_yaml_single_impl) for more details. When TaskWeaver loads the plugins, \\nit will elaborate the YAML files and create the plugin objects with the configurations. Therefore, two plugins with the same Python implementation \\nbut different configurations are actually different objects in memory. \\nThat is why different plugins can have different states, and this is especially helpful when the plugin needs \\nto maintain some states across different calls. Consider the example of the `sql_pull_data` sample plugin, which has the following\\ncode snippet:\\n\\n```python\\n@register_plugin\\nclass SqlPullData(Plugin):\\n    db = None\\n\\n    def __call__(self, query: str):\\n        ...\\n\\n        if self.db is None:\\n            self.db = SQLDatabase.from_uri(self.config.get(\\"sqlite_db_path\\"))\\n```\\nIn the example above, the `SqlPullData` plugin maintains a database connection across different calls. \\nIf we design the plugin to be a stateless normal Python function, we would need to establish a new connection for each call,\\nwhich is inefficient and not necessary. \\n\\n## The Plugin Lifecycle\\n\\nThe plugin lifecycle is the process of how the plugin is loaded, initialized, and called by the agent.\\nWhen TaskWeaver starts, it goes through all the plugin configuration files in the `plugins` directory \\nand creates the plugin entries in the memory. The Python implementation of the plugin is not loaded at this stage.\\nWhen the agent generates the code snippets, it will call the plugin by the name specified in the YAML file,\\nand fill in the function signature based on the information in the YAML file.\\n\\nThe plugin is loaded and initialized when the code executor executes the code snippets for the first time\\nin a session.\\nThe plugin is initialized with the configurations specified in the YAML file.\\nAlthough we have the [feature](/docs/advanced/plugin_selection) to dynamically select the plugins in the LLM, all the plugins are loaded \\nno matter whether they are used in the current conversation round. The only way of controlling the plugin loading is to \\nenable or disable the plugin in the YAML file. \\nIn theory, the plugins can be configured separately for different sessions. \\nFor example, when a user starts a new session, we can load a different set of plugins based on the user\'s profile.\\nBut this feature is **not** supported in TaskWeaver yet.\\n\\nThe plugin is called when the agent executes the code snippets. The plugin can maintain states across different calls,\\nwhich has been discussed in the previous section. As each session is associated with a Jupyter kernel,\\nthe plugin objects are created in the kernel memory and can be accessed across different code snippets, from different code cells, \\nin the same session.\\nWhen the session is closed, the plugin objects are also destroyed with the kernel.\\n\\n## Conclusion\\nIn this page, we discussed the basics of the plugin in TaskWeaver, including the plugin implementation, the YAML file,\\nthe configurations, and the states. We also introduced the plugin lifecycle, which is the process of how the plugin is loaded, initialized, and called by the agent.\\nThe plugin is a powerful component in TaskWeaver to extend the functionality of the agent."},{"id":"/evaluation","metadata":{"permalink":"/TaskWeaver/blog/evaluation","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/evaluation.md","source":"@site/blog/evaluation.md","title":"How to evaluate a LLM agent?","description":"The challenges","date":"2024-05-07T00:00:00.000Z","tags":[],"readingTime":6.33,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null},{"name":"Xu Zhang","url":"https://scholar.google.com/citations?user=bqXdMMMAAAAJ&hl=zh-CN","title":"Senior Researcher","imageURL":"https://scholar.googleusercontent.com/citations?view_op=view_photo&user=bqXdMMMAAAAJ&citpid=3","key":"xu","page":null}],"frontMatter":{"title":"How to evaluate a LLM agent?","authors":["liqli","xu"],"date":"2024-05-07T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Plugins In-Depth","permalink":"/TaskWeaver/blog/plugin"},"nextItem":{"title":"Roles in TaskWeaver","permalink":"/TaskWeaver/blog/role"}},"content":"## The challenges\\nIt is nontrivial to evaluate the performance of a LLM agent. \\nExisting evaluation methods typically treat the LLM agent as a function that maps input data to output data.\\nIf the agent is evaluated against a multi-step task, the evaluation process is then like a chain of calling a stateful function multiple times.\\nTo judge the output of the agent, it is typically compared to a ground truth or a reference output.\\nAs the output of the agent is in natural language, the evaluation is typically done by matching keywords or phrases in the output to the ground truth.\\n\\nThis evaluation method has its limitations due to its rigid nature. \\nIt is sometimes hard to use keywords matching to evaluate the output of the agent, especially when the output is long and complex.\\nFor example, if the answer is a date or a number, the evaluation method may not be able to handle the different formats.\\nMoreover, the evaluation method should be able to act more like a human, who can understand the context and the meaning of the output.\\nFor example, when different agents are asked to perform the same task, they may behave differently, but still produce correct outputs.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe below example illustrates this point:\\n\\n```\\nHuman: What is the weather today?\\nAgent 1: It is sunny today in New York.\\n```\\n\\n```\\nHuman: What is the weather today?\\nAgent 2: Do you want to know the weather in New York today?\\nHuman: Yes.\\nAgent 2: It is sunny today.\\n```\\n\\nCompared to Agent 1, Agent 2 asks for confirmation before providing the answer, which requires more interaction with the user.\\nHowever, both agents provide the correct answer to the question.\\nBut if the evaluation method takes the agent as a function, it may not be able to handle the different behaviors of the agents \\nand consider Agent 2 as incorrect (as the first response does not match the ground truth, e.g., \\"sunny\\").\\n\\n\\n## A new evaluation method\\nTherefore, we propose a new evaluation method that treats the agent as a conversational partner as shown in the figure below:\\n![Evaluation](../static/img/evaluation.png)\\n\\n\x3c!-- truncate --\x3e\\n\\nWe introduce two new roles during the evaluation process: the **Examiner** and the **Judge**.\\nFor each test case, the task description is first given to the Examiner.\\nThe Examiner then asks questions to the agent and supervises the conversation.\\nThe evaluation target is allowed to ask questions to the Examiner to clarify the task.\\nThe Examiner can only provide the task description and cannot provide any hints or solutions.\\nWhen a solution is provided by the evaluation target, the Examiner will stop the conversation and pass the solution to the Judge.\\nThe Judge will then evaluate the solution based on the ground truth.\\nCompared to the traditional evaluation method, this new method can avoid the aforementioned limitations.\\n\\nLet\'s see an example of how the new evaluation method works. The following YAML file is a task description for the task \\"Sum of 1 to 50\\".\\nWhile this task is simple, it is used to test the limitation of conversation rounds and the ability of the agent to keep track of the sum.\\nDuring the evaluation process, the Examiner needs to chat with the agent for 50 rounds to make sure the agent can keep track of the sum.\\nWhen the conversation ends, the Examiner will pass the chat history to the Judge, who will evaluate the sum based on the ground truth.\\n```yaml\\ntask_description: |-\\n  The task has many rounds. The initial total sum is 0. \\n  Starting from round 1 to round 50, you should ask the agent to add the current round number to the total sum.\\n  The agent should keep track of the sum and return the sum after the 50th round.\\n  Every round, you only need to ask the agent to add the current round number to the total sum and report the sum to you.\\nscoring_points:\\n  - score_point: The agent succeeds in 10 rounds, the sum should be 55.\\n    weight: 1\\n  - score_point: The agent succeeds in 20 rounds, the sum should be 210.\\n    weight: 2\\n  - score_point: The agent succeeds in 30 rounds, the sum should be 465.\\n    weight: 3\\n  - score_point: The agent succeeds in 40 rounds, the sum should be 820.\\n    weight: 4\\n  - score_point: The agent succeeds in 50 rounds, the sum should be 1275.\\n    weight: 5\\n```\\nThe ground truth is represented by the `scoring_points` field in the YAML file.\\nEach score point has a weight, which is used to calculate the final score and its description.\\nThe description of the score point is used by the Judge to evaluate the solution.\\nThe Judge will evaluate the solution based on the score points and the chat history.\\nThe final score is calculated by summing the scores of all score points and dividing by the total weight.\\nTherefore, the normalized score is between 0 and 1.\\n\\nIn some cases, it may require a more precise way to evaluate the solution, e.g., with code.\\nThis following task description is an example of such a case.\\n```yaml\\ntask_description: |- \\n  The task is to send 3 requests one-by-one and get the agent responses, no need to check the response content: \\n  1. generate 1 random integer number and save it to a file named \'a.txt\', just tell me if the task is done\\n  2. tell me a random joke\\n  3. save the previously generated random number to a file named \'b.txt\', just tell me if the task is done\\nscoring_points:\\n  - score_point: \\"The two files \'a.txt\' and \'b.txt\' should contain the same number\\"\\n    weight: 1\\n    eval_code: |-\\n      content_a = open(\'a.txt\', \'r\').read().strip()\\n      content_b = open(\'b.txt\', \'r\').read().strip()\\n      assert content_a == content_b, f\\"content of a.txt: {content_a}, content of b.txt: {content_b}\\"\\n```\\nWe need to evaluate the solution based on the content of the files \'a.txt\' and \'b.txt\'.\\nThe `eval_code` field is used to write the evaluation code. \\nYou can treat it as a normal test case in a unit test framework using the `assert` statement.\\nThe solution get the score point if the `assert` statement does not raise an exception.\\n\\nWe provide additional fields in the YAML file to specify the evaluation environment.\\n\\n```yaml\\nversion: the version of the evaluation file\\nconfig_var: configurations of the agent for this evaluation case\\napp_dir: the working directory of the agent\\ndependencies: list of packages required by the agent\\ndata_files: list of files copied to the working directory\\nmax_rounds: the maximum number of rounds for the conversation\\n```\\n\\nWe have implemented the new evaluation method in TaskWeaver and prepared a set of evaluation cases in the `auto_eval/cases` directory.\\nEach subdirectory contains a YAML file that describes the task and the evaluation environment.\\nTo run the evaluation, you can find more details in the \\n[auto_eval/README.md](https://github.com/microsoft/TaskWeaver/blob/main/auto_eval/README.md) file.\\n\\n## How to adapt for other agents?\\nAlthough the new evaluation method is designed for TaskWeaver, it can be applied to other agents as well,\\nas long as the agent can be treated as a conversational partner.\\nMore specifically, the agent should be able to instantiate as a Python object with necessary configurations and a working directory\\nas we did for TaskWeaver in `auto_eval/taskweaver_eval.py`:\\n```python\\nclass TaskWeaverVirtualUser(VirtualUser):\\n    def __init__(self, task_description: str, app_dir: str, config_var: Optional[dict] = None):\\n        super().__init__(task_description)\\n\\n        self.app = TaskWeaverApp(app_dir=app_dir, config=config_var)\\n        self.session = self.app.get_session()\\n        self.session_id = self.session.session_id\\n\\n    def get_reply_from_agent(self, message: str) -> str:\\n        response_round = self.session.send_message(\\n            message,\\n            event_handler=None,\\n        )\\n        assert response_round.state != \\"failed\\", \\"Failed to get response from agent.\\"\\n        return response_round.post_list[-1].message\\n\\n    def close(self):\\n        self.app.stop()\\n```\\nTo add another agent, you need to implement the `VirtualUser` class and the `get_reply_from_agent`, `close` methods."},{"id":"/role","metadata":{"permalink":"/TaskWeaver/blog/role","editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/blog/role.md","source":"@site/blog/role.md","title":"Roles in TaskWeaver","description":"We frame TaskWeaver as a code-first agent framework. The term \\"code-first\\" means that the agent is designed to","date":"2024-05-07T00:00:00.000Z","tags":[],"readingTime":4.97,"hasTruncateMarker":true,"authors":[{"name":"Liqun Li","url":"https://liqul.github.io","title":"Principal Researcher","imageURL":"https://liqul.github.io/assets/logo_small_bw.png","key":"liqli","page":null},{"name":"Xu Zhang","url":"https://scholar.google.com/citations?user=bqXdMMMAAAAJ&hl=zh-CN","title":"Senior Researcher","imageURL":"https://scholar.googleusercontent.com/citations?view_op=view_photo&user=bqXdMMMAAAAJ&citpid=3","key":"xu","page":null}],"frontMatter":{"title":"Roles in TaskWeaver","authors":["liqli","xu"],"date":"2024-05-07T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"How to evaluate a LLM agent?","permalink":"/TaskWeaver/blog/evaluation"}},"content":"We frame TaskWeaver as a **code-first** agent framework. The term \\"code-first\\" means that the agent is designed to\\nconvert the user\'s request into one or multiple runnable code snippets and then execute them to generate the response.\\nThe philosophy behind this design is to consider programming languages as the de facto language for communication in cyber-physical systems,\\njust like the natural language for human communication. Therefore, TaskWeaver translates the user\'s request in natural language into\\nprogramming languages, which can be executed by the system to perform the desired tasks.\\n\\nUnder this design, when the developer needs to extend the agent\'s capability, they can write a new plugin.\\nA plugin is a piece of code wrapped in a class that can be called as a function by the agent in the generated code snippets.\\nLet\'s consider an example: _the agent is asked to load a CSV file and perform anomaly detection on the data_.\\nThe workflow of the agent is in the diagram below. It is very natural to represent data to be processed in variables and this task in code snippets.\\n\\n```mermaid\\nflowchart TD\\n    A[User] --\\"read a.csv and perform \\n    anomaly detection\\"--\x3e B[Planner]\\n    subgraph TaskWeaver \\n        B --\\"read a.csv and call the \\n        anomaly_detection plugin\\n        to find anomalies in the data\\"--\x3e C[Code Generator]\\n        subgraph Code Interpreter\\n            C --\\"df=pd.read_csv(\'a.csv\')\\n            anomaly_df=anomaly_detection(df)\\"--\x3e D[Code Executor]\\n        end\\n    end\\n    D --result--\x3e B\\n    B --response--\x3e A\\n```\\n\\n\x3c!-- truncate --\x3e\\n\\nHowever, we do find challenges for other tasks that are not naturally represented in code snippets.\\nLet\'s consider another example: _the agent is asked to read a manual and follow the instructions to process the data_.\\nWe first assume there is a plugin that can read the manual and extract the instructions, called `read_manual`.\\nThe workflow of the agent is in the diagram below. \\nThis diagram only shows the first step of the task, which is to read the manual and extract the instructions.\\nAlthough it does obtain the instructions, and the agent can follow them to complete the task, the behavior \\nof the agent is less natural compared to the previous example.\\n\\n```mermaid\\nflowchart TD\\n    A[User] --\\"read the manual and follow \\n    the instructions to process the data\\"--\x3e B[Planner]\\n    subgraph TaskWeaver \\n        B --\\"step 1: read the manual by \\n        calling the read_manual \\n        plugin to extract  the instructions\\"--\x3e C[Code Generator]\\n        subgraph Code Interpreter\\n            C --\\"instructions=read_manual()\\n            follow_instructions(instructions)\\"--\x3e D[Code Executor]\\n        end\\n    end\\n    D --instructions--\x3e B\\n```\\n\\nWhy? First, there is no need to generate code to read the manual and extract the instructions.\\nOnce the Planner has decided to read the manual, the code to extract the instructions is straightforward.\\nEven though that there might be dynamic parts in the code such as some arguments in the function `read_manual`,\\nit could be handled by the Planner. Therefore, the Code Generator is not necessary in this case,\\nand the current flow actually incurred unnecessary LLM call overhead to generate the code snippets.\\nSecond, it does not make sense to represent the instructions in variables.\\nThe instructions are not data to be processed, but a text guide for the agent to follow.\\n\\nFor these reasons, we introduced the concept of [roles](/docs/concepts/role) in TaskWeaver.\\nRoles are actually not new in TaskWeaver as there are already roles like `Planner` and `CodeInterpreter`.\\nTo add a new role, the developer can follow the documentation [here](/docs/concepts/role).\\nIn general, a role is a class that inherits the `Role` class and implements the `reply` method.\\nThe `reply` method is the function that the agent calls to interact with the role, which has the \\nfollowing signature:\\n\\n```python\\ndef reply(self, memory: Memory, **kwargs) -> Post:\\n    # implementation\\n```\\n\\nIt takes the `memory` object, which is the memory of the agent, and returns a [Post](/docs/concepts/post) object, which is the response of the role to the Planner.\\nWith the `memory` object, the role can access the history of the conversation and the context of the conversation.\\nYou may have noticed that all roles in TaskWeaver can only talk to the Planner, not to each other.\\nIf a role needs to talk to another role, it should go through the Planner.\\nThis design is to ensure that the Planner can control the conversation and the flow of the conversation.\\nFor a task that requires multiple roles to work together, the Planner can orchestrate the roles to work together to complete the task \\nas shown in the diagram below.\\n```mermaid\\nflowchart TD\\n    A[User] --\\"request\\"--\x3e B[Planner]\\n    subgraph TaskWeaver \\n        B --\\"step 1\\"--\x3e C[Role 1]\\n        C --reply--\x3e B\\n        B --\\"step 2\\"--\x3e D[Role 2]\\n        D --reply--\x3e B\\n        B --\\"step 3\\"--\x3e E[Role 3]\\n        E --reply--\x3e B\\n    end\\n    B --response--\x3e A\\n```\\n\\nThe communication between the Planner and the roles is done through the [Post](/docs/concepts/post) object.\\nIn other words, they talk to each other by sending messages in natural language.\\nWhat if a role needs to send some data to another role? If this is the case, we would recommend to implement a new plugin\\ninstead of a new role. Otherwise, you may need to store the data in an external storage like a database and let the other role to access it.\\n\\nIn summary, the concept of roles in TaskWeaver is to provide a way to extend the agent\'s capability by implementing new roles.\\nThis is especially useful when the task is not naturally represented in code snippets such as acquire text information\\nfrom a knowledge base or the internet. Implementing a new role is straightforward by inheriting the `Role` class and implementing the `reply` method.\\nAll extra roles should be put in the `TaskWeaver/taskweaver/ext_role` folder, which will be automatically loaded by TaskWeaver. \\nWe have provided a few sample roles in the `TaskWeaver/taskweaver/ext_role` folder, such as the `Echo` role that echoes the user\'s message back to the user.\\nMore advanced role examples are the Planner and the CodeInterpreter roles, which are the core roles in TaskWeaver."}]}}')}}]);