"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[625],{10797:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"advanced/compression","title":"Prompt Compression","description":"After chatting for a few rounds, the chat history can become quite long, especially when we have code and execution results in it.","source":"@site/docs/advanced/compression.md","sourceDirName":"advanced","slug":"/advanced/compression","permalink":"/TaskWeaver/docs/advanced/compression","draft":false,"unlisted":false,"editUrl":"https://github.com/microsoft/TaskWeaver/tree/main/website/docs/advanced/compression.md","tags":[],"version":"current","frontMatter":{},"sidebar":"documentSidebar","previous":{"title":"Handcrafted Experience","permalink":"/TaskWeaver/docs/customization/experience/handcrafted_experience"},"next":{"title":"Auto Plugin Selection","permalink":"/TaskWeaver/docs/advanced/plugin_selection"}}');var o=t(74848),s=t(28453);const a={},i="Prompt Compression",d={},h=[{value:"Configurations",id:"configurations",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"prompt-compression",children:"Prompt Compression"})}),"\n",(0,o.jsx)(n.p,{children:"After chatting for a few rounds, the chat history can become quite long, especially when we have code and execution results in it.\nThis can cause the problem of exceeding the context window of the LLMs.\nTo solve the problem, one way is to summarize the chat history a few rounds ago,\nand only keep the latest rounds of the chat history."}),"\n",(0,o.jsx)(n.p,{children:"Another way is to use a vector database to store the chat history entries, and only retrieve the last few rounds of the relevant\npart given the current user request. However, in TaskWeaver, code is also part of the chat history.\nIt is not an option to skip some intermediate code and execution results in order to correctly\ngenerate the code for the current user request. Therefore, we choose the first way to solve the problem."}),"\n",(0,o.jsx)(n.p,{children:"The following figure shows the idea of chat history summarization where the chat history is divided into two parts:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Rounds to compress: this part is summarized and only the summary is kept in the chat history. If the context_summary\nalready exists, a new summary is generated based on the previous summary adding the rounds to be summarized."}),"\n",(0,o.jsx)(n.li,{children:"Rounds to retain: this part is kept in the chat history without summarization."}),"\n"]}),"\n",(0,o.jsx)(n.mermaid,{value:"  flowchart LR\n      ConversationSummary--\x3eRound1\n      subgraph Rounds to compress \n          Round1--\x3eRound2\n      end\n      subgraph Rounds to retain\n          Round2--\x3eRound3--\x3eRound4--\x3eRound5    \n      end"}),"\n",(0,o.jsxs)(n.p,{children:["Imagine that, at the beginning, the ConversationSummary is empty.\nOnce the chat history reaches the ",(0,o.jsx)(n.code,{children:"rounds_to_compress"})," (default 2) rounds plus ",(0,o.jsx)(n.code,{children:"rounds_to_retain"})," (default 3) rounds,\nthe ConversationSummary is generated based on the ",(0,o.jsx)(n.code,{children:"rounds_to_compress"})," rounds and the ",(0,o.jsx)(n.code,{children:"rounds_to_retain"})," rounds are kept in the chat history.\nAfter that, there will be only ",(0,o.jsx)(n.code,{children:"rounds_to_retain"})," rounds in the chat history.\nThe next time the chat history reaches the ",(0,o.jsx)(n.code,{children:"rounds_to_compress"})," rounds plus ",(0,o.jsx)(n.code,{children:"rounds_to_retain"})," rounds,\nthe ConversationSummary is generated based on the ",(0,o.jsx)(n.code,{children:"rounds_to_compress"})," rounds and the previous ConversationSummary.\nWe use these two parameters to control the frequency of the chat history summarization."]}),"\n",(0,o.jsx)(n.p,{children:"An example of the chat history summarization in the Code Generator is shown below:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "ConversationSummary": "The user requested the generation of 100 random numbers, which was successfully executed. Then, the user asked to show the top 5 largest numbers from the generated random numbers. The assistant provided a code snippet to sort the generated random numbers in descending order and select the top 5 largest numbers, which was also successfully executed. After that, the user requested to plot the distribution of the 100 numbers, which was successfully executed. The user then asked to count the frequency of numbers in each bin of the histogram and identify the bin with the most numbers for the 0.1 bin width, which was also successfully executed.",\n  "Variables": [\n    {\n      "name": "random_numbers_100",\n      "type": "numpy array",\n      "description": "An array containing 100 random numbers generated using np.random.rand()"\n    },\n    {\n      "name": "top_5_largest",\n      "type": "numpy array",\n      "description": "An array containing the top 5 largest numbers from the generated random numbers"\n    }\n  ]\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"The JSON object has two fields:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"ConversationSummary: the summary of the chat history."}),"\n",(0,o.jsx)(n.li,{children:"Variables: the variables in the chat history that could be used in the current user request."}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The chat history summary of the Planner has only the ConversationSummary field."}),"\n",(0,o.jsx)(n.p,{children:"The actual code generated in the summarized rounds is ignored and only the variables are kept in the summary\nso that the LLM can still refer the these variables in future code generation."}),"\n",(0,o.jsxs)(n.p,{children:["One thing to note is that chat history summarization requires call the LLM which incurs additional latency and cost.\nThe prompts for chat history summarization could be found for ",(0,o.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:t(37654).A+"",children:"planner"}),"\nand ",(0,o.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:t(68389).A+"",children:"code generator"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"configurations",children:"Configurations"}),"\n",(0,o.jsxs)(n.p,{children:["As explained above, there are two parameters in controlling the chat history summarization:\n",(0,o.jsx)(n.code,{children:"round_compressor.rounds_to_compress"})," (default 2) and ",(0,o.jsx)(n.code,{children:"round_compressor.rounds_to_retain"})," (default 3).\nTo enable the chat history summarization, you need to set ",(0,o.jsx)(n.code,{children:"planner.prompt_compression"}),"\nand ",(0,o.jsx)(n.code,{children:"code_generator.prompt_compression"})," to ",(0,o.jsx)(n.code,{children:"true"}),"."]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var r=t(96540);const o={},s=r.createContext(o);function a(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),r.createElement(s.Provider,{value:n},e.children)}},37654:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/files/compression_prompt-ec8be8772eecf748c3334962442a1a73.yaml"},68389:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/files/compression_prompt-b02606dbb37ec1a39beb98a2d45cad99.yaml"}}]);